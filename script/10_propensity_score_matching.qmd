---
title: ""
format:
  html:
    embed-resources: true
    page-layout: full
    grid:
      margin-width: 100px
author: Daniel Väisänen
editor: source
toc: true
execute:
  warning: false
  echo: true
  eval: false
---


# Project description


## Script: Propensity Score Matching for HPI vs. General Population (1995–2021)
Description:
This script performs yearly 4:1 propensity score matching to compare the
HPI intervention population with the general Swedish population using
demographic covariates (Sex, Birth Year, Education). It ensures unique matches
per year, checks covariate balance, and prepares matched datasets for
downstream analysis and register-based follow-up.

## Outputs:
- Yearly matchit objects (.rds)
- Combined matched dataset with cluster IDs
- Covariate balance statistics
- Summary tables for comparison



#-------------------------
## Libraries

```{r}
library(tidyverse) # Includes dplyr, ggplot2, readr, etc.
library(MatchIt) # For propensity score matching
library(here) # For relative file paths
library(dtplyr) # For lazy_dt and data.table backend
library(data.table) # For efficient data handling with fread and rbindlist
library(tictoc) # For timing operations
library(progress) # For progress bars
library(cobalt) # For covariate balance checking
library(gtsummary) # For summary tables
```




#-------------------------
# Description

Propensity score matching from the total population per year vs the HPI population. 4 to 1.

The propensity score matching will be on variables Sex, birthyear, (Year), and Education.

#-------------------------
## Create comparison dataset from 26 datasets with data from Statistics Sweden
Iterate over datasets to extract and combine necessary variables
```{r}

# Define a function to extract desired variables from each dataset
extract_variables <- function(file_path) {
  dataset <- read_csv(file_path)
  # Extract the year from the file name
  year <- str_extract(basename(file_path), "\\d{4}")  # Extracting the first four digits (year)
  # Extract LopNr, and variables starting with sun, Kon, Age
  extracted_data <- dataset %>%
    select(LopNr, Kommun, KommunSize, starts_with("edu"), starts_with("EducationLevel"),  starts_with("Kon"), starts_with("Age"), starts_with("Fodelse")) %>%
    mutate(Year = year)  # Add the year as a new column
  return(extracted_data)
}

# Define the folder path using here
file_directory <- here("..", "..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "2.filtered")

# List all CSV files in the specified directory
file_list <- list.files(file_directory, pattern = "*.csv", full.names = TRUE)

# Initialize an empty data frame for the final dataset
final_dataset <- tibble()

# Iterate through each file and extract variables
for (file in file_list) {
  # Extract variables from the current dataset
  current_data <- extract_variables(file)

  # Combine with the final dataset
  final_dataset <- bind_rows(final_dataset, current_data)
}

# View the final dataset
print(final_dataset)

write_csv(final_dataset, here::here("..", "data", "scb_match_population.csv"))

```

## Data check

```{r}
final_dataset %>% distinct(LopNr, Year) %>% nrow()

```
# ##############################################################################
# ##############################################################################



# Read in data from comparison population and HPA Population and recode them to match eachother

```{r}
# Enable multi-threading in data.table
setDTthreads(parallel::detectCores())

# Read hpa_df using data.table's fread and convert to tibble
hpa_df <- fread(
  here::here("..", "data", "hpa_pop_one_time_point_clean_20240528.csv"),
  select = c("LopNr", "Sex", "Year", "FodelseAr", "SUN2000Niva_Old")
) %>% as_tibble() %>%
  filter(Year >= 1995 & Year < 2022)

# Create a lazy_dt object for pop_df
pop_dt <- fread(
  here::here("..", "data", "scb_match_population.csv"),
  select = c("LopNr", "Kon", "Year", "FodelseAr", "edu"),
  na.strings = c("", "NA"),
  showProgress = TRUE
)

pop_df <- lazy_dt(pop_dt) %>%
  drop_na() %>%
  mutate(
    SUN2000Niva_Old = edu,
    Sex = Kon,
  # FodelseLandEU28 = FodelseLand_EU28,
    Sex=if_else(Sex == 1, "Men", "Women")
  ) %>%
  select(LopNr, Sex, Year, FodelseAr, SUN2000Niva_Old) %>%
  filter(Year >= 1995 & Year < 2022) %>%
  as.data.table()

# Add 'treated' flag
hpa_df <- hpa_df %>% mutate(treated = 1) %>% as.data.table()
pop_df <- pop_df %>% mutate(treated = 0)

# Combine datasets using data.table's rbindlist
combined_data <- rbindlist(list(hpa_df, pop_df), use.names = TRUE, fill = TRUE)

# Convert categorical columns to factors
categorical_cols <- c("Sex", "SUN2000Niva_Old", "treated") #" FodelseLandEU28",
combined_data[, (categorical_cols) := lapply(.SD, as.factor), .SDcols = categorical_cols]

```

# Propensity score matching
Iterate over years to use the matchIt function by year in a memmory efficient way.

https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html#ref-vanderweele2019
https://kosukeimai.github.io/MatchIt/reference/distance.html


```{r}

# Convert combined_data to data.table for efficient processing
combined_data <- as.data.table(combined_data)


# Adjust the conversion based on data's current encoding, for exampleConvert logical to numeric
# combined_data[, treated := as.numeric(treated)]

# Define the years
years <- sort(unique(combined_data$Year))

# Initialize the progress bar
pb <- progress_bar$new(
  format = "  Processing Year :year [:bar] :percent in :elapsed",
  total = length(years), clear = FALSE, width = 60
)

# Create a log file to record progress and any errors
log_con <- file("processing_log.txt", open = "wt")
writeLines(paste("Processing started at", Sys.time()), con = log_con)

# Initialize an empty vector to keep track of matched IDs
matched_ids <- c()

for (year in years) {
  # Start timing for the current year
  tic(paste("Processing Year:", year))

  # Subset data for the current year and exclude already matched individuals
  subset_data <- combined_data[Year == year & !(LopNr %in% matched_ids)]

  # Check if 'treated' is binary in this subset
  unique_treated <- unique(subset_data$treated)
  unique_treated <- unique_treated[!is.na(unique_treated)]  # Remove NA for checking

  if (length(unique_treated) != 2 || !all(unique_treated %in% c(0, 1))) {
    # Log the error and skip to the next iteration
    message_text <- paste("Error processing Year", year, ": The treatment must be a binary variable. Found values:", paste(unique_treated, collapse = ", "))
    writeLines(message_text, con = log_con)
    message(message_text)

    # Update the progress bar
    pb$tick(tokens = list(year = year))

    # Skip processing for this year
    next
  }

  # Run matchit without including Year in the formula
  nearest_neighbor_match <- tryCatch({
    matchit(
      treated ~ Sex + FodelseAr + SUN2000Niva_Old,
      data = subset_data,
      method = "nearest",
      distance = "glm",
      link = "logit",
      ratio = 4,
      replace = FALSE
    )
  }, error = function(e) {
    # Log the error and skip to the next iteration
    message_text <- paste("Error processing Year", year, ":", e$message)
    writeLines(message_text, con = log_con)
    message(message_text)
    return(NULL)
  })

  # Stop timing for the current year
  toc()

  if (!is.null(nearest_neighbor_match)) {
    # Save the matchit object to disk
    saveRDS(nearest_neighbor_match, paste0("matchit_results_", year, ".rds"))

    # Extract matched data
    matched_data <- match.data(nearest_neighbor_match)

    # Update the list of matched IDs with both treated and control individuals
    matched_ids <- c(matched_ids, matched_data$LopNr)

    # Ensure matched_ids remains unique
    matched_ids <- unique(matched_ids)

    # Log the successful processing
    message_text <- paste("Year", year, "processed successfully. Matched IDs added.")
    writeLines(message_text, con = log_con)
    message(message_text)
  }

  # Clear memory
  rm(nearest_neighbor_match, subset_data, matched_data)
  gc()

  # Update the progress bar
  pb$tick(tokens = list(year = year))
}

# Close the log file
writeLines(paste("Processing completed at", Sys.time()), con = log_con)
close(log_con)
```


# Check if the results are balenced
Can be run from here
```{r}



# 1. where the .rds files live
match_dir <- here("..", "data", "matchit_objects")

# 2. list all files that look like  matchit_results_1998.rds  etc.
rds_files <- list.files(
  path       = match_dir,
  pattern    = "^matchit_results_\\d{4}\\.rds$",
  full.names = TRUE
)

# 3. loop, compute balance, keep rownames
balance_long <- map_dfr(rds_files, function(fp) {
  yr <- str_extract(basename(fp), "\\d{4}") |> as.integer()

  bal_obj <- readRDS(fp) |> bal.tab(un = TRUE)   # compute balance
  bal_tbl <- bal_obj$Balance                     # extract the table

  bal_tbl |>
    tibble::rownames_to_column("covariate") |>
    mutate(year = yr)
})

# 4. save the result for later use
write_csv(balance_long, here("..", "data", "combined_balance_stats.csv"))



```

# read .rds files and put them into one dataset

```{r}

# Define the directory containing the .rds files
rds_directory <- here()

# List all .rds files matching the pattern
rds_files <- list.files(
  path = rds_directory,
  pattern = "^matchit_results_\\d{4}\\.rds$",
  full.names = TRUE
)

# Function to read and process each .rds file
process_rds <- function(file_path) {
  # Extract year from filename
  year <- str_extract(basename(file_path), "\\d{4}") %>% as.integer()

  # Read the MatchIt object
  matchit_obj <- readRDS(file_path)

  # Extract matched data
  matched_data <- match.data(matchit_obj)

  # Add Year information
  matched_data <- matched_data %>%
    mutate(Year = year)

  return(matched_data)
}

# Initialize progress bar
pb <- progress_bar$new(
  format = "  Processing [:bar] :percent in :elapsed",
  total = length(rds_files),
  clear = FALSE,
  width = 60
)

# Modified process_rds function to update progress bar
process_rds_with_progress <- function(file_path) {
  pb$tick()  # Update progress bar
  process_rds(file_path)
}

# Apply the function to all .rds files and combine into one tibble
combined_matched_data <- rds_files %>%
  set_names() %>%
  map_dfr(process_rds_with_progress)      # Combine into a single tibble by row-binding

# Save the combined matched data to disk
# saveRDS(combined_matched_data, here("data", "combined_matched_data.rds"))

# Save as a CSV for easier access
write_csv(combined_matched_data, here("combined_matched_data.csv"))



```


# Create id for matched data

```{r}
combined_matched_data <-
  combined_matched_data |>
  group_by(Year, subclass) |>
  mutate(id_cluster = cur_group_id()) |>
  ungroup()

```


# Save data

```{r}
write_csv(combined_matched_data, here("..", "data", "combined_matched_data.csv"))
```

# Read data
```{r}
combined_matched_data <- read_csv(here::here("..", "data", "combined_matched_data.csv"))

```


# Data for SCB-datauttag

```{r}
reg_ut <- combined_matched_data |> select(LopNr, Year, treated, id_cluster)

write_csv(reg_ut, here::here("..", "data", "registeruttagdata_2025-01-16.csv"))


```


# Table
Calculate differences between the matched and unmatched data
```{r}


library(gtsummary)

  tbl_summary(
    combined_matched_data,
    include = c(Sex, FodelseAr, Year, SUN2000Niva_Old),
    by = treated, # split table by group
    missing = "no" # don't list missing data separately
  ) |>
  add_n() |> # add column with total number of non-missing observations
  add_p() |> # test for a difference between groups
  modify_header(label = "**Variable**") |> # update the column header
  bold_labels()


# duplicated id numbers
  combined_matched_data %>% filter(treated == 0) %>% group_by(LopNr) %>% summarise(number_with_same_id = n()) %>% count(number_with_same_id)


combined_matched_data %>%
  ggplot(aes(x = SUN2000Niva_Old, fill = treated, group = treated)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of SUN2000Niva_Old by treatment group",
       x = "SUN2000Niva_Old",
       y = "Count") +
  theme_minimal()


combined_matched_data %>%
  ggplot(aes(x = FodelseAr, fill = as.factor(treated), group = as.factor(treated))) +
  geom_density(position = position_dodge(width = 1), alpha=.5) +
  facet_wrap(~Year) +
  labs(title = "Distribution of birth year by treatment group",
       x = "SUN2000Niva_Old",
       y = "Count") +
  theme_minimal()

```


## Education Balance

```{r}

balance_long <-
read_csv(here("..", "data", "combined_balance_stats.csv"))


edu_bal <- balance_long |>
  filter(str_detect(covariate, "SUN2000Niva|^edu|EducationLevel")) |>
  arrange(year)

# quick view
print(edu_bal %>% select(year, covariate, Diff.Un, Diff.Adj), n = Inf)

# optional visual check
edu_bal |>
  ggplot(aes(year, Diff.Adj)) +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = c(-.1, .1), linetype = "dotted") +
  geom_point() +
  geom_line() +
  facet_wrap(~ covariate, scales = "free_y") +
  labs(y = "standardized mean difference after matching",
       x = NULL,
       title = "balance on education covariates by year")
```
